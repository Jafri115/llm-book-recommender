{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis for Book Recommendations\n",
    "\n",
    "In this notebook, we'll use Large Language Models (LLMs) to perform sentiment analysis on book descriptions. This will help us determine the emotional tone of books, which can be used as an additional feature in our recommendation system.\n",
    "\n",
    "## Why Sentiment Analysis?\n",
    "\n",
    "By extracting emotional content from book descriptions, we can:\n",
    "- Allow users to filter books based on their desired emotional tone\n",
    "- Someone looking for an exciting read might choose something suspenseful\n",
    "- Someone wanting to be cheered up might choose something joyful\n",
    "- Provide an additional degree of control for users in our recommender system\n",
    "\n",
    "## Our Approach: Fine-tuned Models\n",
    "\n",
    "We'll classify text into **7 discrete emotion categories**:\n",
    "1. **Anger**\n",
    "2. **Disgust** \n",
    "3. **Fear**\n",
    "4. **Joy**\n",
    "5. **Sadness**\n",
    "6. **Surprise**\n",
    "7. **Neutral** (for text without emotional content)\n",
    "\n",
    "### Fine-tuning vs Zero-shot Classification\n",
    "\n",
    "Instead of using zero-shot classification, we're using a **fine-tuned model**. Here's how fine-tuning works:\n",
    "\n",
    "1. Start with a pre-trained model (like RoBERTa) with its encoder layers intact\n",
    "2. Remove the original final layers (used for masked word prediction)\n",
    "3. Replace them with new layers designed for emotion classification\n",
    "4. Train on a labeled emotion dataset\n",
    "5. The model preserves its rich language understanding while learning emotion-specific patterns\n",
    "\n",
    "This gives us an LLM specifically designed for emotion classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "First, let's load our book dataset that contains the predicted categories from previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv('books_with_categories.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Emotion Classification Model\n",
    "\n",
    "We're using a fine-tuned RoBERTa model from Hugging Face: `j-hartmann/emotion-english-distilroberta-base`\n",
    "\n",
    "**Model Details:**\n",
    "- Fine-tuned specifically for 6 basic emotions + neutral class\n",
    "- Evaluation accuracy: **66%** (significantly higher than random chance baseline of 14%)\n",
    "- Well-established model with good performance metrics\n",
    "\n",
    "**Configuration:**\n",
    "- `top_k=None`: Returns all emotion probabilities (not just the top prediction)\n",
    "- `device=0`: Uses GPU for faster processing (change to CPU if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'joy', 'score': 0.9771687984466553},\n",
       "  {'label': 'surprise', 'score': 0.008528691716492176},\n",
       "  {'label': 'neutral', 'score': 0.0057645998895168304},\n",
       "  {'label': 'anger', 'score': 0.004419785924255848},\n",
       "  {'label': 'sadness', 'score': 0.0020923952106386423},\n",
       "  {'label': 'disgust', 'score': 0.0016119939973577857},\n",
       "  {'label': 'fear', 'score': 0.0004138521908316761}]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\",\n",
    "                      model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "                      top_k=None,\n",
    "                      device=0)  # Use device=-1 for CPU\n",
    "\n",
    "# Test the classifier\n",
    "classifier(\"I love this!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Right Granularity: Sentence vs. Whole Description\n",
    "\n",
    "We need to decide at what level to apply sentiment analysis:\n",
    "\n",
    "### Option 1: Whole Description\n",
    "- Analyze the entire book description as one piece\n",
    "- May lose nuanced emotional information\n",
    "\n",
    "### Option 2: Sentence-by-Sentence (Our Choice)\n",
    "- Split description into individual sentences\n",
    "- Analyze each sentence separately\n",
    "- Capture more variety and nuanced emotions\n",
    "- Take maximum probability for each emotion across all sentences\n",
    "\n",
    "Let's test both approaches to see the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A NOVEL THAT READERS and critics have been eagerly anticipating for over a decade, Gilead is an astonishingly imagined story of remarkable lives. John Ames is a preacher, the son of a preacher and the grandson (both maternal and paternal) of preachers. It’s 1956 in Gilead, Iowa, towards the end of the Reverend Ames’s life, and he is absorbed in recording his family’s story, a legacy for the young son he will never see grow up. Haunted by his grandfather’s presence, John tells of the rift between his grandfather and his father: the elder, an angry visionary who fought for the abolitionist cause, and his son, an ardent pacifist. He is troubled, too, by his prodigal namesake, Jack (John Ames) Boughton, his best friend’s lost son who returns to Gilead searching for forgiveness and redemption. Told in John Ames’s joyous, rambling voice that finds beauty, humour and truth in the smallest of life’s details, Gilead is a song of celebration and acceptance of the best and the worst the world has to offer. At its heart is a tale of the sacred bonds between fathers and sons, pitch-perfect in style and story, set to dazzle critics and readers alike.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first book description\n",
    "books[\"description\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WHOLE DESCRIPTION ANALYSIS ===\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== WHOLE DESCRIPTION ANALYSIS ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m whole_result = classifier(books[\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDominant emotion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mwhole_result\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhole_result[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThis might miss nuanced emotional content in different sentences.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Approach 1: Classify entire description\n",
    "print(\"=== WHOLE DESCRIPTION ANALYSIS ===\")\n",
    "whole_result = classifier(books[\"description\"][0])\n",
    "print(f\"Dominant emotion: {whole_result[0]['label']} ({whole_result[0]['score']:.2%})\")\n",
    "print(\"\\nThis might miss nuanced emotional content in different sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 2: Classify by sentences\n",
    "print(\"=== SENTENCE-BY-SENTENCE ANALYSIS ===\")\n",
    "sentences_result = classifier(books[\"description\"][0].split(\".\"))\n",
    "print(\"This captures much more variety:\")\n",
    "for i, sentence_emotions in enumerate(sentences_result[:3]):  # Show first 3 sentences\n",
    "    top_emotion = max(sentence_emotions, key=lambda x: x['score'])\n",
    "    print(f\"Sentence {i+1}: {top_emotion['label']} ({top_emotion['score']:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Individual Sentences\n",
    "\n",
    "Let's look at specific sentences to verify our classifier is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = books[\"description\"][0].split(\".\")\n",
    "predictions = classifier(sentences)\n",
    "\n",
    "print(\"=== SENTENCE ANALYSIS ===\")\n",
    "print(f\"First sentence: '{sentences[0]}'\")\n",
    "print(f\"Prediction: {predictions[0]}\")\n",
    "print()\n",
    "print(f\"Fourth sentence: '{sentences[3]}'\")\n",
    "print(f\"Prediction: {predictions[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Challenge: Multiple Emotions per Book\n",
    "\n",
    "The sentence-by-sentence approach introduces complexity:\n",
    "- Each book now has multiple emotions associated with it\n",
    "- The classifier output is ordered by score (different order for each sentence)\n",
    "\n",
    "**Our Solution:**\n",
    "1. Create separate columns for each of the 7 emotion categories\n",
    "2. For each emotion, take the **highest probability** from across all sentences in the description\n",
    "3. This gives us a comprehensive emotion profile for each book\n",
    "\n",
    "### Data Processing Steps:\n",
    "1. Sort predictions by label (to ensure consistent ordering)\n",
    "2. Extract maximum score for each emotion across all sentences\n",
    "3. Create a structured dataframe with emotion columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the ordering problem\n",
    "print(\"=== ORDERING CHALLENGE ===\")\n",
    "print(\"Raw predictions have different label orders:\")\n",
    "print(f\"Sentence 1 order: {[p['label'] for p in predictions[0]]}\")\n",
    "print(f\"Sentence 2 order: {[p['label'] for p in predictions[1]]}\")\n",
    "print()\n",
    "print(\"After sorting by label:\")\n",
    "sorted_pred = sorted(predictions[0], key=lambda x: x[\"label\"])\n",
    "print(f\"Consistent order: {[p['label'] for p in sorted_pred]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Emotion Extraction System\n",
    "\n",
    "Now we'll create the infrastructure to process all our book descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define our emotion categories (alphabetical order for consistency)\n",
    "emotion_labels = [\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"]\n",
    "\n",
    "# Initialize storage for results\n",
    "isbn = []  # To merge back with original dataframe\n",
    "emotion_scores = {label: [] for label in emotion_labels}  # Dictionary to become dataframe columns\n",
    "\n",
    "def calculate_max_emotion_scores(predictions):\n",
    "    \"\"\"\n",
    "    Extract maximum emotion scores from sentence-level predictions.\n",
    "    \n",
    "    Args:\n",
    "        predictions: List of predictions, one per sentence\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with maximum score for each emotion across all sentences\n",
    "    \"\"\"\n",
    "    # Initialize storage for this description\n",
    "    per_emotion_scores = {label: [] for label in emotion_labels}\n",
    "    \n",
    "    # Process each sentence\n",
    "    for prediction in predictions:\n",
    "        # Sort to ensure consistent emotion order\n",
    "        sorted_predictions = sorted(prediction, key=lambda x: x[\"label\"])\n",
    "        \n",
    "        # Extract score for each emotion\n",
    "        for index, label in enumerate(emotion_labels):\n",
    "            per_emotion_scores[label].append(sorted_predictions[index][\"score\"])\n",
    "    \n",
    "    # Return maximum score for each emotion\n",
    "    return {label: np.max(scores) for label, scores in per_emotion_scores.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Our Function\n",
    "\n",
    "Let's verify our emotion extraction function works correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the first book\n",
    "sentences = books[\"description\"][0].split(\".\")\n",
    "predictions = classifier(sentences)\n",
    "max_scores = calculate_max_emotion_scores(predictions)\n",
    "\n",
    "print(\"=== MAXIMUM EMOTION SCORES ===\")\n",
    "for emotion, score in max_scores.items():\n",
    "    print(f\"{emotion.capitalize()}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing All Books\n",
    "\n",
    "Now let's apply our emotion analysis to the entire dataset. This will take some time as we're processing over 5,000 book descriptions:\n",
    "\n",
    "**Process for each book:**\n",
    "1. Extract ISBN13 for merging later\n",
    "2. Split description into sentences\n",
    "3. Get emotion predictions for all sentences\n",
    "4. Calculate maximum scores for each emotion\n",
    "5. Store results in our data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Reset our storage (in case we're re-running)\n",
    "emotion_labels = [\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"]\n",
    "isbn = []\n",
    "emotion_scores = {label: [] for label in emotion_labels}\n",
    "\n",
    "# Process all books with progress bar\n",
    "for i in tqdm(range(len(books)), desc=\"Analyzing emotions\"):\n",
    "    # Store ISBN for merging\n",
    "    isbn.append(books[\"isbn13\"][i])\n",
    "    \n",
    "    # Process description\n",
    "    sentences = books[\"description\"][i].split(\".\")\n",
    "    predictions = classifier(sentences)\n",
    "    max_scores = calculate_max_emotion_scores(predictions)\n",
    "    \n",
    "    # Store results\n",
    "    for label in emotion_labels:\n",
    "        emotion_scores[label].append(max_scores[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Merging the Emotions DataFrame\n",
    "\n",
    "Convert our results into a pandas DataFrame and merge it back with our original book data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create emotions dataframe\n",
    "emotions_df = pd.DataFrame(emotion_scores)\n",
    "emotions_df[\"isbn13\"] = isbn\n",
    "\n",
    "print(\"=== EMOTIONS DATAFRAME ===\")\n",
    "print(f\"Shape: {emotions_df.shape}\")\n",
    "print(emotions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with original books dataframe\n",
    "books = pd.merge(books, emotions_df, on=\"isbn13\")\n",
    "\n",
    "print(\"=== MERGED DATAFRAME ===\")\n",
    "print(f\"Shape: {books.shape}\")\n",
    "print(\"\\nNew emotion columns:\")\n",
    "print([col for col in books.columns if col in emotion_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the Results\n",
    "\n",
    "Let's look at the distribution of emotions across our book dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display emotion statistics\n",
    "print(\"=== EMOTION DISTRIBUTION STATISTICS ===\")\n",
    "emotion_stats = books[emotion_labels].describe()\n",
    "print(emotion_stats)\n",
    "\n",
    "print(\"\\n=== KEY INSIGHTS ===\")\n",
    "print(\"- We have a good distribution across most emotions\")\n",
    "print(\"- Sadness shows quite high probabilities in many books\")\n",
    "print(\"- This gives us valuable variables for book filtering and recommendation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Enhanced Dataset\n",
    "\n",
    "Save our enriched dataset with emotion features for use in the final recommendation dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv(\"books_with_emotions.csv\", index=False)\n",
    "print(\"✅ Enhanced dataset saved as 'books_with_emotions.csv'\")\n",
    "print(f\"📊 Final dataset shape: {books.shape}\")\n",
    "print(f\"🎭 Emotion features added: {emotion_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We've successfully implemented sentiment analysis for our book recommendation system:\n",
    "\n",
    "1. **Fine-tuned Model**: Used a specialized emotion classification model (66% accuracy)\n",
    "2. **Granular Analysis**: Analyzed emotions at sentence level for better precision\n",
    "3. **Comprehensive Features**: Created 7 emotion columns for each book\n",
    "4. **Smart Aggregation**: Used maximum probability across sentences for each emotion\n",
    "5. **Enhanced Dataset**: Added emotion features to support advanced filtering\n",
    "\n",
    "This sentiment analysis capability showcases how LLMs can extract meaningful features from text data that wouldn't be available in traditional recommender systems!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
